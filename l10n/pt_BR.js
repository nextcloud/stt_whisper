OC.L10N.register(
    "stt_whisper",
    {
    "Whisper Speech-To-Text" : "Sussurro Fala-Para-Texto",
    "Speech-To-Text provider running OpenAI Whisper locally" : "Provedor Fala-Para-Texto executando o OpenAI Whisper localmente",
    "Status" : "Status",
    "Machine learning models have been downloaded successfully." : "Os modelos de aprendizado de máquina foram baixados com sucesso.",
    "The machine learning models still need to be downloaded (see below)." : "Os modelos de aprendizado de máquina ainda precisam ser baixados (veja abaixo).",
    "It seems that your server processor does not support AVX instructions. Without AVX instructions this app currently does not work." : "Parece que o processador do seu servidor não oferece suporte às instruções do AVX. Sem as instruções do AVX, este aplicativo atualmente não funciona.",
    "Background Jobs are not executed via cron. This app requires background jobs to be executed via cron." : "Trabalhos em segundo plano não são executados via cron. Este aplicativo requer que trabalhos em segundo plano sejam executados via cron.",
    "The app was installed successfully and will transcribe files in background processes on request." : "O aplicativo foi instalado com sucesso e irá transcrever arquivos em processos em segundo plano mediante solicitação.",
    "Scheduled transcription Jobs: {scheduled}" : "Tarefas de transcrição agendadas: {scheduled}",
    "Transcription job currently running" : "Tarefa de transcrição em execução no momento",
    "No transcription job currently running" : "Nenhum trabalho de transcrição em execução no momento",
    "Whisper" : "Sussurrar",
    "Select the machine learning model to be used for Speech-To-Text transcription. The larger the model the more resources like RAM, CPU and time are needed. However, the smaller the model, the less accurate the results will be. To use a model you need to download it using the following command:" : "Selecione o modelo de aprendizado de máquina a ser usado para a transcrição de fala para texto. Quanto maior o modelo, mais recursos como RAM, CPU e tempo são necessários. No entanto, quanto menor o modelo, menos precisos serão os resultados. Para usar um modelo, você precisa baixá-lo usando o seguinte comando:",
    "Small model (~1GB RAM, ~1x recording time, ~10-20% word error rate)" : "Modelo pequeno (~1GB RAM, ~1x tempo de gravação, ~10-20% taxa de erro de palavra)",
    "Medium model (~2GB RAM, ~3x recording time, ~7-15% word error rate)" : "Modelo médio (~2 GB de RAM, ~3x tempo de gravação, ~7-15% de taxa de erro de palavra)",
    "Large model (~3.5GB RAM, ~5x recording time, ~4-12% word error rate)" : "Modelo grande (~3,5 GB de RAM, ~5x tempo de gravação, ~4-12% de taxa de erro de palavra)",
    "The number of threads to use (for both transcoding media files to audio as well as the transcription process)" : "O número de threads a serem usados ​​(tanto para a transcodificação de arquivos de mídia para áudio quanto para o processo de transcrição)",
    "FFmpeg" : "FFmpeg",
    "Checking FFmpeg" : "Checando FFmpeg",
    "FFmpeg executable was installed successfully and works." : "O executável FFmpeg foi instalado com sucesso e funciona.",
    "Failed to load settings" : "Erro ao carregar configurações",
    "Failed to save settings" : "Erro ao salvar configurações"
},
"nplurals=3; plural=(n == 0 || n == 1) ? 0 : n != 0 && n % 1000000 == 0 ? 1 : 2;");
