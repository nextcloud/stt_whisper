OC.L10N.register(
    "stt_whisper",
    {
    "Whisper Speech-To-Text" : "Dictado a texto Whisper",
    "Could not execute the FFmpeg executable. You may need to set the path to a working executable manually in the \"Whisper Speech-To-Text app\" section of the admin settings." : "No se pudo ejecutar el ejecutable de FFmpeg. Es probable que necesite establecer la ruta a un ejecutable funcional manualmente en la sección \"Whisper app de Dictado a texto\" de las configuraciones de administración.",
    "Could not execute the Whisper executable. You may need to compile Whisper yourself for it to run on this server's processor architecture." : "No se pudo ejecutar el ejecutable Whisper. Es posible que necesite compilar Whisper por su cuenta para que se ejecute en la arquitectura del procesador de este servidor.",
    "It seems that your server processor does not support AVX instructions. Without AVX instructions Whisper app currently does not work." : "Al parecer, el procesador de su servidor no soporta las instrucciones AVX. Sin las instrucciones AVX esta app actualmente no funciona.",
    "Whisper Speech-To-Text app binary files are present" : "Los archivos binarios de la app Whisper de Dictado a texto están presentes",
    "Whisper Speech-To-Text models are downloaded" : "Los modelos de Whisper Dictado a texto están descargados",
    "Whisper Speech-To-Text models are not downloaded, please run `occ stt_whisper:download-models [small%1$smedium%1$slarge]` to download them" : "Los modelos de Whisper Dictado a texto no están descargados, por favor, ejecute `occ stt_whisper:download-models [small%1$smedium%1$slarge]` para descargarlos",
    "Speech-To-Text provider running OpenAI Whisper locally" : "Proveedor de dictado a texto corriendo Whisper de OpenAI localmente",
    "Speech-To-Text provider running OpenAI Whisper locally\n\nThe models run completely on your machine. No private data leaves your servers.\n\nRequirements:\n * Architecture: x86-64 with AVX support\n * OS: Linux\n\nModel sizes:\n\n* Small: 500MB\n* Medium: 1.5Gb\n* Large: 3.1GB\n\nAfter installing this app you will need to run\n\n    occ stt_whisper:download-models [model-name]\n\nwhere [model-name] is one of\n\n * small\n * medium (default)\n * large\n\n## Ethical AI Rating\n### Rating: 🟡\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n\nNegative:\n* the training data is not freely available, limiting the ability of external parties to check and correct for bias or optimise the model’s performance and CO2 usage.\n\nLearn more about the Nextcloud Ethical AI Rating [in our blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/).\n\nNOTE:\n\nA few things to keep in mind.\n\n* Transcriptions need to be enabled in the Talk app if you need the calls to be transcribed with any Speech to Text provider (including this app). It can be set using this `occ` command:\n\n```\nocc config:app:set spreed call_recording_transcription --value yes\n```\n\n* This app tends to be heavy on CPU. If it starts to be an issue in your normal workflow, you can limit the number of threads used by Whisper in the \"Whisper Speech-To-Text\" section in the admin settings\n* The generated transcriptions may vary in accuracy based on the spoken language.\n* Per participant transcription in calls is currently not available but PRs are welcome!" : "Proveedor de Dictado a texto ejecutando Whisper de OpenAI localmente\n\nLos modelos se ejecutan enteramente en su máquina. Ningún dato privado abandona sus servidores.\n\nRequerimientos:\n * Arquitectura: x86-64 con soporte AVX\n * SO: Linux\n\nTamaños de Modelo:\n\n* Pequeño: 500MB\n* Mediano: 1.5Gb\n* Grande: 3.1GB\n\nLuego de instalar esta app necesitará ejecutar\n\n    occ stt_whisper:download-models [model-name]\n\ndónde [model-name] is uno de\n\n * small\n * medium (predeterminado)\n * large\n\n## Clasificación ética mediante IA\n### Clasificación: 🟡\n\nPositiva:\n* el software para entrenamiento e inferencia de este modelo es de código abierto\n* el modelo entrenado está disponible de forma gratuita, puede ser ejecutado en su infraestructura local\n\nNegativa:\n* los datos de entrenamiento no están disponibles de forma gratuita, limitando la habilidad de terceros de verificar y corregir el bias u optimizar el rendimiento del modelo y uso de CO2.\n\nAprenda más sobre la clasificación ética mediante IA de Nextcloud [en nuestro blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/).\n\nNOTA:\n\nAlgunas cosas para tener en mente.\n\n* Las transcripciones necesitan ser habilitadas en la app Talk si necesita que las llamadas sean transcritas con cualquier proveedor de dictado a texto (incluyendo esta app). Puede configurarse utilizando este comando `occ`:\n\n```\nocc config:app:set spreed call_recording_transcription --value yes\n```\n\n* Esta app suele tener un uso elevado del CPU. Si comienza a ser un problema en su flujo de trabajo normal, puede limitar el número de hilos de ejecución utilizados por Whisper en la sección de \"Whisper app de Dictado a texto\" de las configuraciones de administración\n* Las precisión de las transcripciones generadas podría variar en función del lenguaje hablado.\n* La Transcripción de llamadas basada en participantes individuales actualmente no está disponible, pero, ¡los PRs son bienvenidos!",
    "Status" : "Estatus",
    "Machine learning models have been downloaded successfully." : "Los modelos de machine learning han sido descargados exitosamente.",
    "The machine learning models still need to be downloaded (see below)." : "Los modelos de machine learning todavía requieren ser descargados (vea abajo).",
    "Could not execute the FFmpeg executable. You may need to set the path to a working executable manually. (See below.)" : "No se pudo ejecutar el ejecutable de FFmpeg. Es probable que necesite establecer la ruta a un ejecutable funcional manualmente. (Ver más abajo)",
    "Could not execute the Whisper executable. You may need to compile whisper yourself for it to run on this server's processor architecture." : "No se pudo ejecutar el ejecutable Whisper. Es posible que necesite compilar Whisper por su cuenta para que se ejecute en la arquitectura del procesador de este servidor.",
    "It seems that your server processor does not support AVX instructions. Without AVX instructions this app currently does not work." : "Al parecer, el procesador de su servidor no soporta las instrucciones AVX. Sin las instrucciones AVX esta app actualmente no funciona.",
    "Background Jobs are not executed via cron. This app requires background jobs to be executed via cron." : "Los trabajos en segundo plano no están siendo ejecutados a través de cron. Esta app requiere que los trabajos en segundo plano sean ejecutados a través de cron.",
    "The app was installed successfully and will transcribe files in background processes on request." : "Esta app fue instalada de manera exitosa y transcribirá los archivos en procesos en segundo plano bajo solicitud.",
    "Scheduled transcription Jobs: {scheduled}" : "Trabajos de transcripción programados: {scheduled}",
    "Transcription job currently running" : "Tarea de transcripción actualmente en curso",
    "No transcription job currently running" : "No hay ninguna tarea de transcripción en curso.",
    "Whisper" : "Whisper",
    "Select the machine learning model to be used for Speech-To-Text transcription. The larger the model the more resources like RAM, CPU and time are needed. However, the smaller the model, the less accurate the results will be. To use a model you need to download it using the following command:" : "Seleccione el modelo de machine learning que se usará para la transcripción de dictado a texto. Mientras más grande sea el modelo, más recursos como RAM, CPU y tiempo serán necesarios. Sin embargo, si el modelo es más pequeño, los resultados serán menos precisos. Para usar un modelo, necesita descargarlo utilizando el siguiente comando:",
    "Small model (~1GB RAM, ~1x recording time, ~10-20% word error rate)" : "Modelo pequeño (~1GB RAM, ~1x tiempo de grabación, ~10-20% tasa de error de palabras)",
    "Medium model (~2GB RAM, ~3x recording time, ~7-15% word error rate)" : "Modelo mediano (~2GB RAM, ~3x tiempo de grabación, ~7-15% tasa de error de palabras)",
    "Large model (~3.5GB RAM, ~5x recording time, ~4-12% word error rate)" : "Modelo grande (~3.5GB RAM, ~5x tiempo de grabación, ~4-12% tasa de error de palabras)",
    "The number of threads to use (for both transcoding media files to audio as well as the transcription process)" : "El número de hilos de ejecución a utilizar (tanto para hacer transcodificación de los archivos de medios a audio, así como para el proceso mismo de transcripción)",
    "FFmpeg" : "FFmpeg",
    "Checking FFmpeg" : "Verificando FFmpeg",
    "Could not execute the shipped FFmpeg executable. You may need to set the path to a working binary manually." : "No se pudo ejecutar el ejecutable FFmpeg incluido. Es posible que deba configurar manualmente la ruta a un binario funcional.",
    "FFmpeg executable was installed successfully and works." : "El ejecutable de FFmpeg fue instalado exitosamente y funciona.",
    "If the shipped FFmpeg executable doesn't work on your system for some reason you can set the path to a custom FFmpeg executable. Leave this empty to use the shipped executable." : "Si el ejecutable FFmpeg incluido no funciona en tu sistema por alguna razón, puedes configurar la ruta a un ejecutable de FFmpeg personalizado. Deje este campo vacío para usar el ejecutable incluido.",
    "Failed to load settings" : "Fallo al cargar configuraciones",
    "Failed to save settings" : "Fallo al guardar configuraciones"
},
"nplurals=3; plural=n == 1 ? 0 : n != 0 && n % 1000000 == 0 ? 1 : 2;");
