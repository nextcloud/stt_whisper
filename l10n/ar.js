OC.L10N.register(
    "stt_whisper",
    {
    "Whisper Speech-To-Text" : "ØªØ·Ø¨ÙŠÙ‚ \"Ø§Ù„Ù‡Ø§Ù…Ø³\" Whisper Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù† ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ",
    "Speech-To-Text provider running OpenAI Whisper locally" : "Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù† ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI Whisper ØªØ¹Ù…Ù„ Ù…Ø­Ù„Ù‘ÙŠÙ‘Ø§Ù‹",
    "Speech-To-Text provider running OpenAI Whisper locally\n\nThe models run completely on your machine. No private data leaves your servers.\n\nRequires:\n\n * Architecture: x86_64\n * OS: Linux\n\nAfter installing this app you will need to run\n\n    occ stt_whisper:download-models [model-name]\n\nwhere [model-name] is one of\n\n * small\n * medium (default)\n * large\n\n## Ethical AI Rating\n### Rating: ðŸŸ¡\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n\nNegative:\n* the training data is not freely available, limiting the ability of external parties to check and correct for bias or optimise the modelâ€™s performance and CO2 usage.\n\nLearn more about the Nextcloud Ethical AI Rating [in our blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/)." : "Ù…ÙŒØ²Ù‘ÙÙˆØ¯ \"Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù† ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ\" Speach-To-Text ÙŠÙ‚ÙˆÙ… Ø¨ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… \"Ø§Ù„Ù‡Ø§Ù…Ø³\" Whisper Ù…Ù† OpenAI Ù…Ø­Ù„ÙŠÙ‘Ø§Ù‹ \n\nØªØ¹Ù…Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ. Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§ØµØ© ØªØ®Ø±Ø¬ Ø®Ø§Ø±Ø¬ Ø®ÙˆØ§Ø¯Ù…Ùƒ. \n\nÙŠØªØ·Ù„Ø¨:\n\n * Ø§Ù„Ø¨Ù†ÙŠØ©: x86_64 \n* Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„: Ù„ÙŠÙ†ÙƒØ³\n\nØ¨Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø³ÙˆÙ ØªØ­ØªØ§Ø¬ Ø¥Ù„ÙŠ ØªØ´ØºÙŠÙ„:\n\nocc stt_whisper:ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ [Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬] \n\nØ­ÙŠØ« [Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬] \n\nÙ‡Ùˆ ÙˆØ§Ø­Ø¯ Ù…Ù† \n* ØµØºÙŠØ± \n* Ù…ØªÙˆØ³Ø· (Ø§ÙØªØ±Ø§Ø¶ÙŠ) \n* ÙƒØ¨ÙŠØ± \n\n## ØªÙ‚ÙŠÙŠÙ… AI Ø§Ù„ÙˆØµÙÙŠ\n ### Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: ðŸŸ¡ \n\nØ§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª: \n* Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± \n* Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…ØªØ§Ø­ Ù…Ø¬Ø§Ù†Ù‹Ø§ØŒ ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø¨Ø±Ù…Ø¬ÙŠØ© Ø£ÙˆÙ† Ø¨Ø±ÙŠÙ…Ø³ÙŠØ² \n\nØ§Ù„Ø³Ù„Ø¨ÙŠØ§Øª: \n* Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ù…Ø¬Ø§Ù†Ù‹Ø§ ØŒ Ù…Ù…Ø§ ÙŠØ­Ø¯ Ù…Ù† Ù‚Ø¯Ø±Ø© Ø§Ù„Ø£Ø·Ø±Ø§Ù Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠ ÙˆØªØµØ­ÙŠØ­Ù‡ Ø£Ùˆ ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… CO2. \n\nØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ø­ÙˆÙ„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØµÙÙŠ Ù„Ù†ÙƒØ³Øª ÙƒÙ„ÙˆØ¯ AI [Ù…Ù† Ø®Ù„Ø§Ù„ Ù…Ø¯ÙˆÙ†ØªÙ†Ø§] (https://nextcloud.com/blog/nextcloud-ethical-ai-rating/ ).",
    "Status" : "Ø§Ù„Ø­Ø§Ù„Ù‡",
    "Machine learning models have been downloaded successfully." : "ØªÙ…Ù‘ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø¢Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­.",
    "The machine learning models still need to be downloaded (see below)." : "Ù†Ù…Ø§Ø°Ø¬ ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø¢Ù„Ø© Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø¨Ø¹Ø¯Ù. (Ø£Ù†Ø¸Ø± Ø£Ø¯Ù†Ø§Ù‡).",
    "Could not execute the FFmpeg executable. You may need to set the path to a working executable manually. (See below.)" : "ØªØ¹Ø°Ù‘Ø± ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ FFmpeg. Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ù…Ù„ÙÙ ØªÙ†ÙÙŠØ°ÙŠÙ‘Ù ÙŠØ¹Ù…Ù„ ÙŠØ¯ÙˆÙŠØ§Ù‹. (Ø£Ù†Ø¸Ø± Ø£Ø¯Ù†Ø§Ù‡.)",
    "Could not execute the Whisper executable. You may need to compile whisper yourself for it to run on this server's processor architecture." : "ØªØ¹Ø°Ø± ØªÙ†ÙÙŠØ° Whisper Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ. Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ¬Ù…ÙŠØ¹ Whisper Ø¨Ù†ÙØ³Ùƒ Ù„ØªØ´ØºÙŠÙ„Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø§Ø¯,Ù….",
    "It seems that your server processor does not support AVX instructions. Without AVX instructions this app currently does not work." : "ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø®Ø§Ø¯ÙˆÙ… Ù„Ø§ ÙŠØ¯Ø¹Ù… ØªØ¹Ù„ÙŠÙ…Ø§Øª AVX Ùˆ Ø§Ù„ØªÙŠ Ù„Ù† ÙŠØ¹Ù…Ù„ Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø¯ÙˆÙ†Ù‡Ø§.",
    "Background Jobs are not executed via cron. This app requires background jobs to be executed via cron." : "Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ© Ù„Ø§ ØªØ¹Ù…Ù„ Ø­Ø§Ù„ÙŠÙ‘Ø§Ù‹ Ø¹Ø¨Ø± cron. Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ³ØªÙ„Ø²Ù… ØªØ´ØºÙŠÙ„ Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¹Ø¨Ø± cron.",
    "The app was installed successfully and will transcribe files in background processes on request." : "ØªÙ…Ù‘ ØªÙ†ØµÙŠØ¨ Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ù†Ø¬Ø§Ø­ Ùˆ Ù‡Ùˆ Ù…Ø³ØªØ¹Ø¯ Ù„Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨.",
    "Scheduled transcription Jobs: {scheduled}" : "Ù…Ù‡Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ­ÙˆÙŠÙ„ÙŠØ© Ù…Ø¬Ø¯ÙˆÙ„Ø©: {scheduled}",
    "Transcription job currently running" : "Ù…Ù‡Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ­ÙˆÙŠÙ„ÙŠØ© ØªØ¹Ù…Ù„ Ø­Ø§Ù„ÙŠÙ‘Ø§Ù‹",
    "No transcription job currently running" : "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‡Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ­ÙˆÙŠÙ„ÙŠØ© ØªØ¹Ù…Ù„ Ø­Ø§Ù„ÙŠÙ‘Ø§Ù‹",
    "Whisper" : "ØªØ·Ø¨ÙŠÙ‚ Whisper \"Ù‡Ø§Ù…Ø³\"",
    "Select the machine learning model to be used for Speech-To-Text transcription. The larger the model the more resources like RAM, CPU and time are needed. However, the smaller the model, the less accurate the results will be. To use a model you need to download it using the following command:" : "Ø¥Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø¢Ù„Ø© Ø§Ù„Ø°ÙŠ Ø³ÙŠØ³ØªØ®Ø¯Ù… ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ ÙƒØªØ§Ø¨Ø©. ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ¨Ø± ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙ‡ Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ùˆ Ø§Ù„Ù…ÙØ¹Ø§Ù„Ø¬ Ùˆ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙƒØ¨Ø±. Ùˆ Ø¨Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„ ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§ØµØºØ± ÙƒÙ„Ù…Ø§ ÙƒØ§Ù†Øª Ø¯Ù‚Ù‘ØªÙ‡ Ø£Ù‚Ù„. Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¬Ø¨ ØªÙ†Ø²ÙŠÙ„Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ: ",
    "Small model (~1GB RAM, ~1x recording time, ~10-20% word error rate)" : " Ù†Ù…ÙˆØ°Ø¬ ØµØºÙŠØ± (~1GB RAM, ~1x r Ø²Ù…Ù† Ø§Ù„ØªØ³Ø¬ÙŠÙ„, ~10-20% Ù…ÙØ¹Ø¯Ù‘Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª)",
    "Medium model (~2GB RAM, ~3x recording time, ~7-15% word error rate)" : " Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙˆØ³Ø·  (~2GB RAM, ~3x Ø²Ù…Ù† Ø§Ù„ØªØ³Ø¬ÙŠÙ„, ~7-15% Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª)",
    "Large model (~3.5GB RAM, ~5x recording time, ~4-12% word error rate)" : "Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¨ÙŠØ± (~3.5GB RAM, ~5x Ø²Ù…Ù† Ø§Ù„ØªØ³Ø¬ÙŠÙ„, ~4-12% Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª)",
    "The number of threads to use (for both transcoding media files to audio as well as the transcription process)" : "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù†Ø³Ø§Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ( ØªØ´Ù…Ù„ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ÙŠØ© Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø¥Ù„Ù‰ ØµÙˆØª Ùˆ Ù…Ù† Ø«Ù…Ù‘ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ ÙƒØªØ§Ø¨Ø©)",
    "FFmpeg" : "FFmpeg",
    "Checking FFmpeg" : "Ø§Ø®ØªØ¨Ø§Ø± FFmpeg",
    "Could not execute the shipped FFmpeg executable. You may need to set the path to a working binary manually." : "ØªØ¹Ø°Ø± ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ø§Ù„Ù…Ø´Ø­ÙˆÙ† FFmpeg. Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø£Ù† ØªÙØ¹ÙŠÙ‘ÙÙ† ÙŠØ¯ÙˆÙŠÙ‘Ø§Ù‹ Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø«Ù†Ø§Ø¦ÙŠ ØµØ§Ù„Ø­.",
    "FFmpeg executable was installed successfully and works." : "Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªÙ†ÙÙŠØ° FFmpeg Ù…ÙˆØ¬ÙˆØ¯ Ùˆ ÙŠØ¹Ù…Ù„ ÙƒÙ…Ø§ ÙŠØ¬Ø¨",
    "If the shipped FFmpeg executable doesn't work on your system for some reason you can set the path to a custom FFmpeg executable. Leave this empty to use the shipped executable." : "Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ø§Ù„Ù…Ø´Ø­ÙˆÙ† FFmpeg Ù„Ø§ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ù†Ø¸Ø§Ù…Ùƒ Ù„Ø³Ø¨Ø¨ Ù…Ø§ØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ù…Ù„Ù ØªÙ†ÙÙŠØ°ÙŠ FFmpeg Ù…ÙØ®ØµÙ‘ÙŽØµ. Ø£ØªØ±ÙÙƒ Ù‡Ø°Ø§ ÙØ§Ø±ØºÙ‹Ø§ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ø§Ù„Ù…Ø´Ø­ÙˆÙ†.",
    "Failed to load settings" : "Ø¥Ø®ÙØ§Ù‚ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª",
    "Failed to save settings" : "ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"
},
"nplurals=6; plural=n==0 ? 0 : n==1 ? 1 : n==2 ? 2 : n%100>=3 && n%100<=10 ? 3 : n%100>=11 && n%100<=99 ? 4 : 5;");
