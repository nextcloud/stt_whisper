OC.L10N.register(
    "stt_whisper",
    {
    "Whisper Speech-To-Text" : "Reconnaissance vocale Whisper",
    "Could not execute the FFmpeg executable. You may need to set the path to a working executable manually in the \"Whisper Speech-To-Text app\" section of the admin settings." : "Impossible d'ex√©cuter la commande FFmpeg. Vous devrez peut-√™tre sp√©cifier manuellement le chemin vers un ex√©cutable valable dans la section ¬´ Application Whisper Speech-To-Text ¬ª dans les param√®tres d'administration.",
    "Could not execute the Whisper executable. You may need to compile Whisper yourself for it to run on this server's processor architecture." : "Impossible d'ex√©cuter le bianire Whisper. Vous avez peut-√™tre besoin de le compiler vous-m√™me pour l'ex√©cuter sur l'architecture CPU de votre serveur.",
    "It seems that your server processor does not support AVX instructions. Without AVX instructions Whisper app currently does not work." : "Il semble que le processeur de votre serveur n'est pas compatible avec les instructions AVX. Sans instructions AVX, l'application Whisper ne peut fonctionner.",
    "Whisper Speech-To-Text app binary files are present" : "Les fichiers ex√©cutables Whisper Speech-To-Text sont pr√©sents",
    "Speech-To-Text provider running OpenAI Whisper locally" : "Un fournisseur de reconnaissance vocale utilisant OpenAI localement",
    "Speech-To-Text provider running OpenAI Whisper locally\n\nThe models run completely on your machine. No private data leaves your servers.\n\nRequirements:\n * Architecture: x86-64 with AVX support\n * OS: Linux\n\nModel sizes:\n\n* Small: 500MB\n* Medium: 1.5Gb\n* Large: 3.1GB\n\nAfter installing this app you will need to run\n\n    occ stt_whisper:download-models [model-name]\n\nwhere [model-name] is one of\n\n * small\n * medium (default)\n * large\n\n## Ethical AI Rating\n### Rating: üü°\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n\nNegative:\n* the training data is not freely available, limiting the ability of external parties to check and correct for bias or optimise the model‚Äôs performance and CO2 usage.\n\nLearn more about the Nextcloud Ethical AI Rating [in our blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/)." : "Un outil de reconnaissance vocale utilisant OpenAI localement\n\nLes mod√®les tournent enti√®rement sur votre machine. Aucune donn√©e priv√©e ne sort de vos serveurs.\n\nPr√©requis :\n\n * Architecture: x86_64 avec compatibilit√© AVX\n * Syst√®me d'exploitation: Linux\n\nTaille des mod√®les :\n\n* Petit : 500 Mo\n* Moyen : 1,5 Go\n* Grand : 3,1 Go\n\nApr√®s avoir install√© cette application, vous devrez ex√©cuter\n\n    occ stt_whisper:download-models [nom-du-mod√®le]\n\no√π [nom-du-mod√®le] peut prendre les valeurs\n\n * small\n * medium (par d√©faut)\n * large\n\n## Classification √©thique de l'IA\n### Score : üü°\n\nPoints positifs :\n* le logiciel permettant l'entra√Ænement et l'inf√©rence du mod√®le est en open source\n* le mod√®le d'entra√Ænement est disponible librement, et peut donc √™tre ex√©cut√© localement\n\nPoints n√©gatifs :\n* les donn√©es d'entra√Ænement ne sont pas accessibles librement, ce qui limite les possibilit√©s laiss√©es aux personnes tierces de les v√©rifier et les corriger, afin de corriger les biais et optimiser les performances et le bilan carbone du mod√®le.\n\nApprenez-en plus sur la classification √©thique de l'IA Nextcloud [sur notre blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/).",
    "Status" : "√âtat",
    "Machine learning models have been downloaded successfully." : "Les mod√®les d'IA ont √©t√© t√©l√©charg√©s avec succ√®s.",
    "The machine learning models still need to be downloaded (see below)." : "Les mod√®les d'intelligence artificielle doivent encore √™tre t√©l√©charg√©s (voir ci-dessous).",
    "Could not execute the FFmpeg executable. You may need to set the path to a working executable manually. (See below.)" : "Impossible d'ex√©cuter la commande FFmpeg. Vous devrez peut-√™tre sp√©cifier manuellement le chemin vers un ex√©cutable valable (voir ci-dessous).",
    "Could not execute the Whisper executable. You may need to compile whisper yourself for it to run on this server's processor architecture." : "Impossible d'ex√©cuter le bianire Whisper. Vous avez peut-√™tre besoin de le compiler vous-m√™me pour l'ex√©cuter sur l'architecture CPU de votre serveur.",
    "It seems that your server processor does not support AVX instructions. Without AVX instructions this app currently does not work." : "Il semble que le processeur de votre serveur n'est pas compatible avec les instructions AVX. Sans instructions AVX, cette application ne peut fonctionner.",
    "Background Jobs are not executed via cron. This app requires background jobs to be executed via cron." : "Les t√¢ches en arri√®re-plan ne sont pas ex√©cut√©es avec cron. Cette application exige que ces t√¢ches soient ex√©cut√©es par cron.",
    "The app was installed successfully and will transcribe files in background processes on request." : "L'application a correctement √©t√© install√©e et va transcrire les fichiers dans des processus en arri√®re-plan sur demande.",
    "Scheduled transcription Jobs: {scheduled}" : "Jobs de transcription planifi√©s : {scheduled}",
    "Transcription job currently running" : "Travail de transcription en cours",
    "No transcription job currently running" : "Aucun travail de transcription n'est en cours",
    "Whisper" : "Whisper",
    "Select the machine learning model to be used for Speech-To-Text transcription. The larger the model the more resources like RAM, CPU and time are needed. However, the smaller the model, the less accurate the results will be. To use a model you need to download it using the following command:" : "S√©lectionnez le mod√®le d'apprentissage machine √† utiliser pour la transcription voix en texte. Plus grand est le mod√®le, plus il va consommer de ressources comme la RAM, le processeur et du temps. Cependant, plus petit est le mod√®le, moins le r√©sultat sera pr√©cis. Pour utiliser un mod√®le, vous aurez besoin de le t√©l√©charger en utilisant la commande suivante :",
    "Small model (~1GB RAM, ~1x recording time, ~10-20% word error rate)" : "Petit mod√®le (~1GB de RAM, ~1x temps d'enregistrement, taux d'erreur par mot de ~10-20%)",
    "Medium model (~2GB RAM, ~3x recording time, ~7-15% word error rate)" : "Mod√®le interm√©diaire (~2GB de RAM, ~3x le temps d'enregistrement,  taux d'erreur par mot de~7-15%)",
    "Large model (~3.5GB RAM, ~5x recording time, ~4-12% word error rate)" : "Grand mod√®le (~3.5GB de RAM, ~5x le temps d'enregistrement, taux d'erreur par mot de~4-12%)",
    "The number of threads to use (for both transcoding media files to audio as well as the transcription process)" : "Le nombre de threads √† utiliser (aussi bien pour le transcodage des fichiers que le processus de transcription)",
    "FFmpeg" : "FFmpeg",
    "Checking FFmpeg" : "V√©rification de FFmpeg",
    "Could not execute the shipped FFmpeg executable. You may need to set the path to a working binary manually." : "Impossible d'ex√©cuter l'ex√©cutable FFmpeg fournie avec l'extension. Vous devrez peut-√™tre sp√©cifier un chemin vers une copie fonctionnelle du programme.",
    "FFmpeg executable was installed successfully and works." : "L'ex√©cutable FFmpeg a √©t√© install√© avec succ√®s et fonctionne.",
    "If the shipped FFmpeg executable doesn't work on your system for some reason you can set the path to a custom FFmpeg executable. Leave this empty to use the shipped executable." : "Si pour une raison inconnue l'ex√©cutable FFmpeg livr√© avec l'extension ne fonctionne pas sur votre syst√®me, vous pouvez indiquer le chemin vers un ex√©cutable fonctionnel. Laisser cette case vide pour utiliser la version livr√©e avec cette extension.",
    "Failed to load settings" : "√âchec du chargement des param√®tres",
    "Failed to save settings" : "√âchec de l'enregistrement des param√®tres"
},
"nplurals=3; plural=(n == 0 || n == 1) ? 0 : n != 0 && n % 1000000 == 0 ? 1 : 2;");
